import os
import chromadb
from tqdm import tqdm
from datetime import datetime

# === ì„¤ì • ===
# ë§ˆìš´íŠ¸ëœ ìˆ˜ì‹  ë°ì´í„° ê²½ë¡œ (hltutorì˜ DB)
SOURCE_DIR = "/tmp/tutorchroma" 
# í˜„ì¬ ìš´ì˜ ì¤‘ì¸ hltaì˜ ChromaDB (ì—¬ê¸°ì— í•©ì¹¨)
TARGET_HOST = "hlta-chroma"
TARGET_PORT = 8000
BATCH_SIZE = 500  # ì•ˆì •ì ì¸ ì „ì†¡ì„ ìœ„í•œ ë°°ì¹˜ ì‚¬ì´ì¦ˆ
# ============

def merge_db():
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"ğŸ•’ Merge Timestamp for this batch: {current_time}")
    print(f"ğŸš€ Merge Start: [File] {SOURCE_DIR} -> [Server] {TARGET_HOST}")

    # 1. Source (File) ë¡œë“œ
    if not os.path.exists(os.path.join(SOURCE_DIR, "chroma.sqlite3")):
        print(f"âŒ Source DB not found in {SOURCE_DIR}. Run rsync first.")
        return

    try:
        src_client = chromadb.PersistentClient(path=SOURCE_DIR)
        collections = src_client.list_collections()
        print(f"ğŸ” Source Collections Found: {len(collections)}")
    except Exception as e:
        print(f"âŒ Failed to load source DB: {e}")
        return

    # 2. Target (Server) ì—°ê²°
    try:
        target_client = chromadb.HttpClient(host=TARGET_HOST, port=TARGET_PORT)
        target_client.heartbeat()
        print("âœ… Target Server Connected")
    except Exception as e:
        print(f"âŒ Target Connection Failed: {e}")
        return

    success_cnt = 0

    # 3. ë°ì´í„° ë³‘í•© (Upsert)
    for col in tqdm(collections, desc="Merging Collections"):
        try:
            # Source ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            data = col.get(include=["embeddings", "documents", "metadatas"])
            total_docs = len(data['ids'])
            
            if total_docs == 0:
                continue

            # Target ì»¬ë ‰ì…˜ ì¤€ë¹„ (ì—†ìœ¼ë©´ ìƒì„±)
            dest_col = target_client.get_or_create_collection(
                name=col.name,
                metadata=col.metadata
            )

            # ë°°ì¹˜ ë‹¨ìœ„ Upsert (Insertê°€ ì•„ë‹ˆë¼ Upsert ì‚¬ìš©!)
            for i in range(0, total_docs, BATCH_SIZE):
                end = i + BATCH_SIZE
                
                b_ids = data['ids'][i:end]
                b_embeddings = data['embeddings'][i:end]
                b_documents = data['documents'][i:end] if data['documents'] else None
                # [ìˆ˜ì •ë¨] ë©”íƒ€ë°ì´í„°ì— ë‚ ì§œ ì •ë³´ ì¶”ê°€ ë¡œì§ ---------------------------
                # ì›ë³¸ ë©”íƒ€ë°ì´í„° ìŠ¬ë¼ì´ì‹± (ì—†ìœ¼ë©´ None ë¦¬ìŠ¤íŠ¸ë¡œ ëŒ€ì²´í•˜ì—¬ ì¸ë±ìŠ¤ ë§ì¶¤)
                raw_metas = data['metadatas'][i:end] if data['metadatas'] else [None] * len(b_ids)
                
                b_metadatas = []
                for meta in raw_metas:
                    # ê¸°ì¡´ ë©”íƒ€ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë³µì‚¬, ì—†ìœ¼ë©´ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ìƒì„±
                    new_meta = meta.copy() if meta else {}
                    # ë‚ ì§œ ì •ë³´ ê°•ì œ ì£¼ì…
                    new_meta['last_updated'] = current_time
                    b_metadatas.append(new_meta)
                # ------------------------------------------------------------------
                
                # upsert: IDê°€ ê°™ìœ¼ë©´ ë®ì–´ì“°ê³ , ì—†ìœ¼ë©´ ì¶”ê°€í•¨ (Union íš¨ê³¼)
                dest_col.upsert(
                    ids=b_ids,
                    embeddings=b_embeddings,
                    metadatas=b_metadatas,
                    documents=b_documents
                )
            
            success_cnt += 1

        except Exception as inner_e:
            print(f"âš ï¸ Error merging '{col.name}': {inner_e}")

    print("="*40)
    print(f"ğŸ‰ Merge Completed. Collections processed: {success_cnt}")
    print("="*40)

if __name__ == "__main__":
    merge_db()
